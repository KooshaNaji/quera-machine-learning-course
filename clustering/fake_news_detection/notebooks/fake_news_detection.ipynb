{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "تشخیص اخبار دروغین\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "مطمئنا بارها شنیده‌اید که در فضای مجازی اخبار دروغ و شایعه بسیار رایج است. افرادی هستند که به هر دلیل اقدام به انتشار خبرهای دروغ می‌کنند. برخی این دروغ‌ها از جنس خبرهای سیاسی، اقتصادی یا حواشی راجع به زندگی افراد مشهور و سلبریتی‌هاست. اما به هر نحوی که باشد، دروغ رفتار خوبی نیست.\n",
    "    <br>\n",
    "    پس به عنوان یک مخاطب خوب است که بتوانیم تشخیص دهیم چه خبری حقیقت و چه خبری دروغ است. اگر از دید یک خبرگزاری هم به ماجرا نگاه کنیم، متوجه خواهیم شد که اصلا دوست نداریم یک خبر دروغ اقتصادی یا سیاسی از زبان ما منتشر شود؛ در غیر این صورت عواقب پیشبینی‌نشده‌ای در انتظارمان خواهد بود!\n",
    "    <br>\n",
    "    پس حال که به اهمیت و کاربرد تشخیص اخبار دروغین پی برده‌ایم، خوب است خودمان تلاش کنیم مدلی آموزش دهیم که خبرهای دروغ را از حقیقت جدا کنیم.\n",
    "    <br>\n",
    "    البته تشخیص این امر، وابسته به توانایی پردازش زبان طبیعی است و با دانش یادگیری ماشین کلاسیک، به سادگی نمی‌توان مسئله رو حل کرد. برای اینکه مسئله قابل حل باشد، بخش «پردازش زبان طبیعی» را خود ما انجام داده‌ایم و نتیجه آن‌ را در قالب بخشی از مجموعه‌داده در اختیار شما قرار داده‌ایم.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "وارد کردن کتابخانه‌های مورد نیاز\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.sparse as ss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "مجموعه‌داده این تمرین، مانند تمرین‌های قبلی به دو مجموعه آموزش و آزمون تقسیم‌بندی می‌شود. اما نکته حائز اهمیت این است که هر کدام از این دو مجموعه آزمون و آموزش، خود دارای دو مجموعه داده است. به عبارت بهتر مجموعه آموزش دارای دو مجموعه‌داده به اسم <code>news_train.csv</code> و <code>news_train_text_vectors.npz</code> است (مجموعه آزمون هم همینطور است).\n",
    "    <br>\n",
    "    در فایل <code>news_train.csv</code> اطلاعات کلی مانند زمان انتشار، منبع و برچسب خبر آمده است؛ اما خود خبر را در این مجموعه‌داده نداریم. بلکه خود خبر را می‌توان در فایل <code>news_train_text_vectors.npz</code> جستجو کرد. اما در <code>news_train_text_vectors.npz</code> متن خبر قرار نگرفته است، بلکه به کمک روش‌های پردازش زبان طبیعی، متن هر خبر را به یک بردار ۴۲۱۴۱ المانی تبدیل کرده‌ایم و به ازای هر خبر، یک بردار با ابعاد <code>(42141, 1)</code> وجود دارد.\n",
    "    <br>\n",
    "    توضیحات مجموعه‌داده <code>news_train.csv</code> را در جدول زیر می‌توانید مشاهده کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|author|شخصی که متن خبر را نوشته است|\n",
    "|published|تاریخ و ساعتی که خبر منتشر شده است|\n",
    "|site_url|سایت منتشرکننده خبر|\n",
    "|type|برای هر خبر یک دسته یا یک نوعی نیز ذخیره کرده‌ایم. این ستون می‌تواند یکی از مقادیر `bs` به معنی *پرت* یا ‍‍‍‍`conspiracy` به معنی *توطئه آمیز* یا `bias` به معنی *سوگیری یا متعصبانه* یا `hate` به معنی *نفرت‌افکن یا خشم‌آلود* یا ‍`satrie` به معنی *طنز* یا `junksci` به معنی *به درد نخور یا آشغال* و `fake` به معنی *دروغ* باشد|\n",
    "|label|برچسب خبر را نشان می‌دهد. این ستون یا `Fake` است یا `Real`|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در کنار فایل <code>news_train.csv</code> فایل <code>news_train_text_vectors.npz</code> نیز قرار دارد. کلیات این فایل را در قسمت قبلی توضیح دادیم. به حجیم بودن فایل و صرفه‌جویی درفضای ذخیره‌سازی و کاهش زمان برای بارگذاری فایل، به جای فرمت <code>csv</code> آن را در فرمت <code>npz</code> در اختیار شما قرار دادیم. اما پیشنهاد می‌کنیم برای راحتی خودتان، پس از خواندن فایل، آن را به یک دیتافریم با ۱۵۰۰ سطر و ۴۲۱۴۱ ستون تبدیل کنید.\n",
    "    <br>\n",
    "    اینطور در نظر داشته باشید که متن هر خبر را با ۴۲۱۴۱ ویژگی برایتان توصیف کرده‌ایم!\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در ابتدا نیاز است فایل‌های مجموعه‌داده را بخوانید. نمونه‌های آموزشی در فایل <code>news_train.csv</code> و <code>news_train_text_vectors.npz</code> و نمونه‌های آزمون که باید دسته‌ی آن‌ها را پیش‌بینی کنید در فایل <code>news_test.csv</code> و <code>news_test_text_vectors.npz</code> ذخیره شده‌اند. اگر لازم دانستید می‌توانید به دلخواه خود بخشی از دادگان آموزشی را به عنوان دادگان اعتبارسنجی نیز جدا کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab3c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/news_train.csv')\n",
    "train_data_text_vectors = ss.load_npz('../data/news_train_text_vectors.npz')\n",
    "\n",
    "test_data = pd.read_csv('../data/news_test.csv')\n",
    "test_data_text_vectors = ss.load_npz('../data/news_test_text_vectors.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ea55dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>site_url</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Author</td>\n",
       "      <td>2016-11-01T03:28:50.389+02:00</td>\n",
       "      <td>clickhole.com</td>\n",
       "      <td>satire</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>2016-10-27T21:30:00.000+03:00</td>\n",
       "      <td>abeldanger.net</td>\n",
       "      <td>bs</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kali74</td>\n",
       "      <td>2016-10-27T02:54:49.093+03:00</td>\n",
       "      <td>abovetopsecret.com</td>\n",
       "      <td>bs</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>2016-11-04T22:44:06.026+02:00</td>\n",
       "      <td>amtvmedia.com</td>\n",
       "      <td>bs</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luke Stranahan</td>\n",
       "      <td>2016-11-23T15:10:56.702+02:00</td>\n",
       "      <td>returnofkings.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al Bundy</td>\n",
       "      <td>2016-10-26T19:27:00.000+03:00</td>\n",
       "      <td>prisonplanet.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EdJenner</td>\n",
       "      <td>2016-11-13T06:02:47.949+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-22T21:26:00.000+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No Author</td>\n",
       "      <td>2016-11-05T03:00:36.461+02:00</td>\n",
       "      <td>dailywire.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eric Zuesse.</td>\n",
       "      <td>2016-10-31T05:40:12.397+02:00</td>\n",
       "      <td>westernjournalism.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                      published               site_url  \\\n",
       "0       No Author  2016-11-01T03:28:50.389+02:00          clickhole.com   \n",
       "1       Anonymous  2016-10-27T21:30:00.000+03:00         abeldanger.net   \n",
       "2          Kali74  2016-10-27T02:54:49.093+03:00     abovetopsecret.com   \n",
       "3     Alex Ansary  2016-11-04T22:44:06.026+02:00          amtvmedia.com   \n",
       "4  Luke Stranahan  2016-11-23T15:10:56.702+02:00      returnofkings.com   \n",
       "5        Al Bundy  2016-10-26T19:27:00.000+03:00       prisonplanet.com   \n",
       "6        EdJenner  2016-11-13T06:02:47.949+02:00    100percentfedup.com   \n",
       "7          Fed Up  2016-11-22T21:26:00.000+02:00    100percentfedup.com   \n",
       "8       No Author  2016-11-05T03:00:36.461+02:00          dailywire.com   \n",
       "9    Eric Zuesse.  2016-10-31T05:40:12.397+02:00  westernjournalism.com   \n",
       "\n",
       "         type label  \n",
       "0      satire  Fake  \n",
       "1          bs  Fake  \n",
       "2          bs  Fake  \n",
       "3          bs  Fake  \n",
       "4        hate  Real  \n",
       "5  conspiracy  Fake  \n",
       "6        bias  Real  \n",
       "7        bias  Real  \n",
       "8        bias  Real  \n",
       "9        bias  Real  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec54",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پیش‌پردازش و مهندسی ویژگی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این سوال شما می‌توانید از هر تکنیک پیش‌پردازش/مهندسی ویژگی که در فصل‌های گذشته آموختید، استفاده کنید.\n",
    "    <br>\n",
    "    تکنیک‌هایی که استفاده می‌کنید به شکل مستقیم مورد ارزیابی توسط سامانه داوری قرار <b>نمی‌گیرند.</b> بلکه همه آن‌ها در دقت مدل شما تاثیر خواهند گذاشت؛ بنابراین هر چه پیش‌پردازش/مهندسی ویژگی بهتری انجام دهید تا دقت مدل بهبود پیدا کند، امتیاز بیشتری از این سوال کسب خواهید کرد.\n",
    "    <br>\n",
    "    از آنجایی که قرار است در این تمرین از الگوریتم ماشین بردار پشتیبان استفاده کنید، حتما باید مجموعه‌داده <code>news_train_text_vectors.npz</code> را با روش‌های کاهش ابعادی که یاد گرفته‌اید، به نحوی تغییر دهید که در زمان معقولی توسط الگوریتم <code>svm</code> پردازش شود. اگر چه الگوریتمی که برای کاهش ابعاد استفاده می‌کنید در کوئرا بررسی نمی‌شود، اما پیشنهاد ما استفاده از <code>PCA</code> است. آنچه اهمیت دارد آن است که بین کوچک‌کردن داده و کیفیت مدل تعادل برقرار کنید. طبیعی است که هرچقدر داده کوچک‌تر باشد، احتمالا الگوریتم ماشین بردار پشتیبان زودتر به نتیجه می‌رسد؛ اما در نظر داشته باشید با کاهش بعد، شما عملا بخشی از داده را از دست می‌دهید!\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b90385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessorKoosha:\n",
    "    def __init__(self, train_data, train_data_vectors, test_data, test_data_vectors):\n",
    "        self.train_data = train_data.copy()\n",
    "        self.test_data = test_data.copy()\n",
    "        self.train_data_vectors = train_data_vectors.copy()\n",
    "        self.test_data_vectors = test_data_vectors.copy()\n",
    "\n",
    "    def label_encode(self):\n",
    "        label_dict = {'Real': 0, 'Fake': 1} \n",
    "        self.train_data['label'] = self.train_data['label'].map(label_dict) \n",
    "    \n",
    "    def delete_unnecessary_feature_by_me(self, column:str):\n",
    "        self.train_data.drop(columns=column, axis=1, inplace=True)\n",
    "        self.test_data.drop(columns=column, axis=1, inplace=True)\n",
    "\n",
    "    def mean_encode_then_delete(self, target_feature: str):\n",
    "        feature_mean_label = self.train_data.groupby(target_feature)['label'].mean()\n",
    "        new_feature = target_feature + '_mean_label'\n",
    "        self.train_data[new_feature] = self.train_data[target_feature].map(feature_mean_label)\n",
    "        self.test_data[new_feature] = self.test_data[target_feature].map(feature_mean_label)\n",
    "        global_mean_label = self.train_data['label'].mean()\n",
    "        self.test_data[new_feature] = self.test_data[new_feature].fillna(global_mean_label)\n",
    "        self.train_data.drop(columns=target_feature, axis=1, inplace=True)\n",
    "        self.test_data.drop(columns=target_feature, axis=1, inplace=True)\n",
    "\n",
    "    def concat_dataframes(self):\n",
    "        train_vectors_df = pd.DataFrame(self.train_data_vectors.toarray())\n",
    "        test_vectors_df = pd.DataFrame(self.test_data_vectors.toarray())\n",
    "        \n",
    "        self.train_data.reset_index(drop=True, inplace=True)\n",
    "        self.test_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.train_data = pd.concat([self.train_data, train_vectors_df], axis=1)\n",
    "        self.test_data = pd.concat([self.test_data, test_vectors_df], axis=1)\n",
    "\n",
    "    def split_target(self):\n",
    "        self.train_data_target = self.train_data['label']\n",
    "        self.train_data.drop(columns='label', axis=1, inplace=True)\n",
    "         \n",
    "    def define_validation_data(self, test_size=.2):\n",
    "        (self.train_data, \n",
    "         self.valid_data, \n",
    "         self.train_data_target, \n",
    "         self.valid_data_target) = train_test_split(\n",
    "             self.train_data, \n",
    "             self.train_data_target, \n",
    "             test_size=test_size,\n",
    "             random_state=50\n",
    "         )\n",
    "    \n",
    "    def pca_feature_extraction(self):\n",
    "        pca = PCA()\n",
    "        self.train_data.columns = self.train_data.columns.astype(str)\n",
    "        self.valid_data.columns = self.valid_data.columns.astype(str)\n",
    "        self.test_data.columns = self.test_data.columns.astype(str)\n",
    "        \n",
    "        self.train_data = pca.fit_transform(self.train_data)\n",
    "        self.valid_data = pca.transform(self.valid_data)\n",
    "        self.test_data = pca.transform(self.test_data)\n",
    "\n",
    "    def transform(self):\n",
    "        self.label_encode()\n",
    "        self.delete_unnecessary_feature_by_me(column='published')\n",
    "        to_change_list = ['author', 'site_url', 'type']\n",
    "        for feature in to_change_list:\n",
    "            self.mean_encode_then_delete(target_feature=feature)\n",
    "        self.concat_dataframes()\n",
    "        self.split_target()\n",
    "        self.define_validation_data()\n",
    "        self.pca_feature_extraction()\n",
    "        \n",
    "        return self.train_data, self.train_data_target, self.valid_data, self.valid_data_target, self.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7495f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreprocessorKoosha(train_data=train_data, train_data_vectors=train_data_text_vectors,\n",
    "                                  test_data=test_data, test_data_vectors=test_data_text_vectors)\n",
    "train_data, train_data_target, valid_data, valid_data_target, test_data = preprocessor.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f9f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04f681cf",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    استفاده از <code>scikit-learn</code>\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    الگوریتم <i>تحلیل مولفه‌های اصلی</i> با نام <code>PCA</code> در پکیج <code>decomposition</code> این کتابخانه در دسترس است. برخی از آرگومان‌های مهم آن در جدول زیر آمده است، اما جهت مطالعه‌ی کامل‌تر مستندات می‌توانید به <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" target=\"_blank\">این لینک</a> مراجعه فرمایید.\n",
    "    <br>\n",
    "    برای استفاده از این الگوریتم، می‌توانید با اجرای <code>from sklearn.decomposition import PCA</code> آن را وارد (<code>import</code>) کنید.\n",
    "    <br>\n",
    "    \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "|آرگومان|جنس و تایپ|توضیحات|\n",
    "|:------:|:--------:|:---:|\n",
    "|n_components|<code>int</code> یا <code>float</code>|تعداد مولفه‌هایی است که قصد داریم پس از اجرای الگوریتم، آن‌ها را داشته باشیم و حذف نشوند. اگر به این آرگومان مقدار ندهیم، همه مولفه‌ها حفظ خواهند شد. اگر جنس این آرگومان <code>int</code> باشد، نشانگر تعداد مولفه‌هایی است که قصد داریم حفظ شود. اما اگر از جنس <code>float</code> و به شکل $0< n\\_components< 1$ باشد، به این معنا خواهد بود که به اندازه‌ای از مولفه‌ها حفظ شوند که واریانس داده‌ها بزرگتر از `n_componets`٪ باشد. بنابراین می‌توان اینگونه برداشت کرد که هرچه این عدد به ۱ نزدیک‌تر باشد، چون قرار است داده واریانس زیادی داشته باشد، پس مولفه‌های بیشتری حفظ می‌شوند.|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    کلاس <code>PCA</code> دارای سه متد به شرح زیر است: \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|اسم متد|توضیحات|\n",
    "|:------:|:---:|\n",
    "|fit(X)|الگوریتم را با X که در ابعاد `(n_samples, n_features)` است|\n",
    "|transform(X)|این تابع X که از ابعاد `(n_samples, n_features)` است را به یک ماتریس دیگری با ابعاد `(n_samples, n_components)` تبدیل می‌کند. پس خروجی این تابع یک ماتریس به ابعاد `(n_samples, n_components)` خواهد بود|\n",
    "|fit_transform(X)|ابتدا تابع <code>fit</code> و سپس تابع <code>transform</code> را اجرا می‌کند|\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac91b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2c94",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل‌سازی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال که داده را پاکسازی کرده و احتمالا ویژگی‌هایی را به آن افزوده یا از آن حذف کرده‌اید، وقت آن است که مدلی آموزش دهید که بتواند متغیر هدف این مسئله را پیش‌بینی کند.\n",
    "    <br>\n",
    "    <b>توجه داشته باشید که برای پیشبینی متغیر هدف این مسئله حتما باید از الگوریتم <code>SVM</code> استفاده کنید. در غیر این صورت، نمره‌ای دریافت نخواهید کرد.</b>\n",
    "    <br>\n",
    "    نحوه استفاده از این الگوریتم را در تمرین‌ها و درسنامه‌های قبلی آموخته‌اید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90b4d9",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "آموزش مدل\n",
    "</font>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d5b8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(train_data, train_data_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da5d2a",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معیار ارزیابی\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    معیاری که برای ارزیابی عملکرد مدل انتخاب کرده‌ایم، <code>f1_score</code> نام دارد.\n",
    "    <br>\n",
    "    این معیار، سنجه ارزیابی کیفیت مدل شماست. به عبارت بهتر در سامانه داوری هم از همین معیار برای نمره‌دهی استفاده شده است.\n",
    "    <br>\n",
    "    پیشنهاد می‌شود با توجه به این معیار، عملکرد مدل خود را بر روی دادگان آموزش یا اعتبارسنجی ارزیابی کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad09cf",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    " جهت کسب امتیاز کامل نیاز است تا پاسخ شما حداقل امتیاز <code>80</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c0bf71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid = model.predict(valid_data)\n",
    "\n",
    "f1_score(valid_data_target, pred_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e9984de",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " پیش‌بینی برای داده تست و خروجی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پس از مهندسی ویژگی و مدلسازی، الگوریتمی دارید که می‌تواند شما را از متغیرهای مستقل به متغیر هدف برساند.\n",
    "    <br>\n",
    "    از این مدل برای پیش‌بینی نمونه‌های موجود در داده تست استفاده کنید و نتایج را در قالب جدول (<code>dataframe</code>) زیر آماده کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|------|---|\n",
    "|label|برچسب پیشبینی شده|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6d82d",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اسم دیتافریم باید <i>submission</i> باشد؛ در غیر این صورت، سامانه داوری نمی‌تواند تلاش‌ شما را ارزیابی کند.\n",
    "    <br>\n",
    "    این دیتافریم تنها شامل ۱ ستون با اسم <i>label</i> است و ۳۴۶ سطر دارد.\n",
    "    <br>\n",
    "    به ازای هر سطر موجود در دیتافریم <i>test</i> شما باید یک مقدار پیشبینی شده داشته باشید.\n",
    "    <br>\n",
    "    جدول زیر، ۵ سطر ابتدایی دیتافریم <code>submission</code> را نشان می‌دهد. البته در جواب شما، اعداد ستون <i>label</i> ممکن است متفاوت باشد.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "||label|\n",
    "|----|-----|\n",
    "|0|Fake|\n",
    "|1|Fake|\n",
    "|2|Real|\n",
    "|3|Fake|\n",
    "|4|Real|\n",
    "</font>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae24c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "pred_test = model.predict(test_data)\n",
    "submission['label'] = pred_test\n",
    "\n",
    "label_dict = {0:'Real', 1:'Fake'} \n",
    "submission['label'] = submission['label'].map(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['fake_news_detection.ipynb', 'submission.csv', 'model']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "joblib.dump(model, 'model')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['fake_news_detection.ipynb', 'submission.csv', 'model']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
