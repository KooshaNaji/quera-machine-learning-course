{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù…ÙˆØ¶ÙˆØ¹â€ŒØ¨Ù†Ø¯ÛŒ\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù…Ù‚Ø¯Ù…Ù‡ Ùˆ ØµÙˆØ±Øª Ù…Ø³Ø¦Ù„Ù‡\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Ø¨Ù‡ ÛŒÚ© ØªÙ…Ø±ÛŒÙ† ØµÙ†Ø¹ØªÛŒ Ø§Ø²  Ú©Ø§Ø±Ø¨Ø±Ø¯ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ (NLP) Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.  Ø¯Ø± Ø§ÛŒÙ† ØªÙ…Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ÙˆØ¨ ÙØ§Ø±Ø³ÛŒ Ú©Ù‡ ØªÙˆØ³Ø· Ù¾Ù„ØªÙØ±Ù… <a href=\"https://www.yektanet.com/\">ÛŒÚ©ØªØ§Ù†Øª</a> Ù¾Ø§Ù„Ø§ÛŒØ´ Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ù…Ø§ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØªÙ‡ Ø§Ø³Øª. Ù‡Ø¯Ù ØªÙ…Ø±ÛŒÙ†Ø› Ø³Ø§Ø®Øª ÛŒÚ© Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ÛŒÚ© Ù¾ÛŒÙˆÙ†Ø¯ (Link) Ù†Ø¸ÛŒØ± <i>Ø¹Ù†ÙˆØ§Ù†</i>ØŒ <i>ØªÙˆØ¶ÛŒØ­Ø§Øª</i>ØŒ <i>Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ [Ú©Ø§Ù…Ù„]</i> Ùˆ ØºÛŒØ±Ù‡ Ø¨ØªÙˆØ§Ù†Ø¯ Ø¯Ø³ØªÙ‡â€ŒÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ø¢Ù† Ø³Ù†Ø¯ Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯. Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù…Ø«Ø§Ù„ Ø§Ú¯Ø± Ù¾ÛŒÙˆÙ†Ø¯ÛŒ Ø§Ø² ÛŒÚ© Ø³Ø§ÛŒØª Ø®Ø¨Ø±ÛŒ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Â«<i>Ú©ÛŒÙ‡Ø§Ù† Ú©Ù„Ù‡Ø± Ø¬Ø§ÛŒØ²Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¬Ù‡Ø§Ù† Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯</i>Â» Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…ØŒ Ù…Ø¯Ù„ Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯ Ú©Ù‡ Ø§ÛŒÙ† Ù…Ø·Ù„Ø¨ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ Â«Ù…ÙˆØ³ÛŒÙ‚ÛŒÂ» Ø§Ø³Øª. Ø§Ù„Ø¨ØªÙ‡ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ Ù…Ø§ ØªÙ†Ù‡Ø§ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒ <i>Ø¹Ù†ÙˆØ§Ù†</i> ÛŒØ§Ø¯ Ú©Ø±Ø¯ÛŒÙ…ØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒâ€ŒÚ©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ù…ØªÙ† <i>ØªÙˆØ¶ÛŒØ­Ø§Øª</i> ÛŒØ§ <i>Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ</i> Ù‡Ù… Ú©Ù…Ú© Ú¯Ø±ÙØª. \n",
    "\n",
    "</br>\n",
    "ØªÙˆØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¢Ù†â€ŒÚ©Ù‡ Ø¨ØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø±ÙÛŒâ€ŒØ´Ø¯Ù‡ Ø¯Ø± Ú©Ø§Ù„Ø¬ Ø¬Ù‡Øª Ú©Ø§Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ù†ÛŒØ§Ø² Ø§Ø³Øª Ø­Ø¯Ø§Ù‚Ù„ Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªØ¹Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ (Embedding) Ø¢Ø´Ù†Ø§ Ø´Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯ ØªØ§ Ø¨ØªÙˆØ§Ù†ÛŒØ¯ Ù‡Ø± Ù…ØªÙ† Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ø¹Ø¯Ø¯ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯.\n",
    "\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ø§Ø¨ØªØ¯Ø§ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²ØªØ§Ù† Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù…Ø¹Ø±ÙÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ¯Ø§Ø¯Ù‡\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ø§ÛŒÙ† Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ¯Ø§Ø¯Ù‡ Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø²ÛŒØ± Ø´Ø±Ø­ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø§Ø³Øª. Ø³ØªÙˆÙ† <code>category</code> Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ù…Ø³Ø¦Ù„Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. \n",
    "</font>\n",
    "</p>\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|Ø³ØªÙˆÙ†|ØªÙˆØ¶ÛŒØ­Ø§Øª|\n",
    "|:------:|:---:|\n",
    "|<code>category</code>| Ù…ÙˆØ¶ÙˆØ¹ (Ù…ØªØºÛŒØ± Ù‡Ø¯Ù) |\n",
    "|<code>description</code>| ØªÙˆØ¶ÛŒØ­Ø§Øª |\n",
    "|<code>text_content</code>| Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ |\n",
    "|<code>title</code>| Ø¹Ù†ÙˆØ§Ù† |\n",
    "|<code>h1</code>| Ù…Ø­ØªÙˆØ§ÛŒ ØªÚ¯ <code>h1</code> ØµÙØ­Ù‡ |\n",
    "|<code>h2</code>|Ù…Ø­ØªÙˆØ§ÛŒ ØªÚ¯ <code>h2</code> ØµÙØ­Ù‡  |\n",
    "|<code>url</code>| Ø¢Ø¯Ø±Ø³ Ù¾ÛŒÙˆÙ†Ø¯|\n",
    "|<code>domain</code>|Ø¯Ø§Ù…Ù†Ù‡â€ŒÛŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØª |\n",
    "|<code>id</code>|Ø¢ÛŒØ¯ÛŒ Ù¾ÛŒÙˆÙ†Ø¯|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ Ù†ÛŒØ§Ø² Ø§Ø³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯. Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ <code>yektanet_train.csv</code> Ùˆ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ù…ÙˆØ¶ÙˆØ¹ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†ÛŒØ¯ Ø¯Ø± ÙØ§ÛŒÙ„ <code>yektanet_test.csv</code> Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯. Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¯Ø§Ù†Ø³ØªÛŒØ¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ø®ÙˆØ¯ Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†ÛŒØ² Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/yektanet_train.csv') # To-Do\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/yektanet_test.csv') # To-Do\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ú©Ø§Ø± Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒØŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ú©Ù…Ú© ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ø±Ø§Ø­Ù„ Ø¨Ø³ÛŒØ§Ø± ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø± Ø¯Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ù„ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª.\n",
    "Ø¯Ø± ØªÙ…Ø±ÛŒÙ† Â«Ú©Ø§Ù…Ù†Øªâ€ŒÚ©Ø§ÙˆÛŒÂ» ÙØµÙ„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† ØªÚ©Ù†ÛŒÚ© Ø±Ø§ÛŒØ¬ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø®ØµÙˆØµØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¢Ø´Ù†Ø§ Ø´Ø¯ÛŒØ¯. Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ù†ÛŒØ² Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªØ§Ø¨Ø¹ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ú©Ù‡ ÛŒÚ© Ø±Ø´ØªÙ‡ (<code>string</code>) Ø±Ø§ Ú¯Ø±ÙØªÙ‡ØŒ Ø§ØµÙ„Ø§Ø­Ø§Øª Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø´Ù…Ø§ Ø±Ùˆ Ø±ÙˆÛŒ Ù…ØªÙ† Ø§Ø¹Ù…Ø§Ù„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¨Ø§ ÙØ±Ù…Øª ÛŒÚ© Ø±Ø´ØªÙ‡ (<code>string</code>) Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ù‡Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ¯Ø§Ø¯Ù‡ Ø§Ø² Ù†Ø¸Ø± ØªØ¹Ø¯Ø§Ø¯ Ø±Ø®Ø¯Ø§Ø¯ Ù†ÛŒØ² Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø´Ù…Ø§ Ø±Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ØªØ± ÛŒØ§Ø±ÛŒ Ú©Ù†Ø¯.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingKoosha:\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "\n",
    "    def fill_na_train(self):\n",
    "        cols = ['description', 'h1', 'h2', 'domain']\n",
    "\n",
    "        for col in cols:\n",
    "            most_frequent = self.train[col].value_counts().sort_values(ascending=False).index[0]\n",
    "            self.train[col].fillna(most_frequent, inplace=True)\n",
    "            self.test[col].fillna(most_frequent, inplace=True)\n",
    "        self.train.isna().sum()\n",
    "\n",
    "    def encoding_label(self):    \n",
    "        encoder = LabelEncoder()\n",
    "        self.train['category'] = encoder.fit_transform(self.train['category'])     \n",
    "\n",
    "    def define_train_data_target(self):\n",
    "        self.train_data_target = self.train['category']\n",
    "        self.train.drop(columns='category', axis=1, inplace=True)\n",
    "\n",
    "    def text_embeding(self):\n",
    "        # Difine a tokenizer with hazm library\n",
    "        stopwords = stopwords_list()\n",
    "        punctuations = ['ØŸ', '!', '.', ',', ';', ':', 'ØŒ', 'Ø›', '(', ')', '[', ']', '{', '}', 'Â«', 'Â»', '|', '/']\n",
    "        normalizer = Normalizer()\n",
    "        tokenizer = WordTokenizer()\n",
    "        def hazm_tokenizer(text):\n",
    "            \n",
    "            # Normalize the text\n",
    "            text_normalized = normalizer.normalize(text)\n",
    "            tokens = tokenizer.tokenize(text_normalized)\n",
    "            # tokens = [token for token in tokens if token not in punctuations and token not in stopwords and not token.isdigit()]\n",
    "            tokens = [token for token in tokens if token not in punctuations and token not in stopwords]\n",
    "            return tokens\n",
    "        \n",
    "        # Define a pipeline using countvectorize and tfid\n",
    "        pipe = Pipeline([('count', CountVectorizer(tokenizer=hazm_tokenizer, analyzer='word', ngram_range=(1, 2),\n",
    "                                         min_df=5, lowercase=False)),\n",
    "                        ('tfidf', TfidfTransformer(sublinear_tf=True))])\n",
    "\n",
    "        pipe.fit(self.train['title'])\n",
    "        self.train_data = pipe.transform(self.train['title']).toarray()\n",
    "        self.test_data = pipe.transform(self.test['title']).toarray()\n",
    "\n",
    "\n",
    "    def balance_target(self):\n",
    "        ros = RandomOverSampler()\n",
    "        self.train_data, self.train_data_target = ros.fit_resample(self.train_data, self.train_data_target)\n",
    "\n",
    "    def define_validation_data(self):\n",
    "        self.train_data, self.valid_data, self.train_data_target, self.valid_data_target = train_test_split(\n",
    "            self.train_data, self.train_data_target, test_size=.1)\n",
    "        \n",
    "    def transform(self):\n",
    "        self.fill_na_train()\n",
    "        self.encoding_label()\n",
    "        self.define_train_data_target()\n",
    "        self.text_embeding()\n",
    "        self.balance_target()\n",
    "        self.define_validation_data()\n",
    "\n",
    "        return (self.train_data, self.train_data_target,\n",
    "                self.valid_data, self.valid_data_target,\n",
    "                self.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BLUENOTEBOOK\\Desktop\\media\\ex\\qenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreprocessingKoosha(train=train, test=test)\n",
    "# train_data, test_data = preprocessor.transform()\n",
    "train_data, train_data_target, valid_data, valid_data_target, test_data = preprocessor.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 1879)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12157, 1879)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 1879)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… ØªØ¹Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ Ú©Ù…Ú© Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÛŒ <code>scikit-learn</code>\n",
    "Ø§Ø² Ø¢Ù†Ø¬Ø§ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø² (Tokenizer) Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø§Ø² ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§ÛŒÙ† Ø²Ø¨Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…. Ú©Ø§ÙÛŒØ³Øª ØªØ§Ø¨Ø¹ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ú©Ù‡ ÛŒÚ© Ø±Ø´ØªÙ‡ (<code>string</code>) Ø±Ø§ Ú¯Ø±ÙØªÙ‡ Ùˆ Ø¨Ù‡ Ú©Ù…Ú© Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÛŒ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø´Ù…Ø§ (Ù…Ø«Ù„ <code>word_tokenize</code> Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÛŒ Ù‡Ø¶Ù…) ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø¢Ù† Ø±Ø§ Ø¬Ø¯Ø§ Ú©Ù†Ø¯. Ø®Ø±ÙˆØ¬ÛŒ ØªØ§Ø¨Ø¹ Ù„ÛŒØ³ØªÛŒ Ø§Ø² ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizer(text):\n",
    "#     return None # To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ØªÙˆØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ Ø§Ù†ØªØ®Ø§Ø¨ Ø§ÛŒÙ†â€ŒÚ©Ù‡ Ø§Ø² Ú©Ø¯Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ù…ØªÙ†â€ŒÙ‡Ø§) Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† ÙˆØ±ÙˆØ¯ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡â€ŒÛŒ Ø®ÙˆØ¯ØªØ§Ù† Ø§Ø³Øª. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªÙ†Ù‡Ø§ Ø§Ø² ÛŒÚ© Ø³ØªÙˆÙ† Ù…Ø«Ù„ <code>title</code> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡â€ŒÙ†Ø­ÙˆÛŒ Ù…ØªÙ† ÛŒØ§ Ø­ØªÛŒ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ù‡Ø± Ø³ØªÙˆÙ† Ø±Ø§ Ø¨Ø§ Ù‡Ù…Ø¯ÛŒÚ¯Ø± ØªØ±Ú©ÛŒØ¨ Ú©Ù†ÛŒØ¯. Ù‡Ù…Ú†Ù†ÛŒÙ† ÙØ±Ø§Ù…ÙˆØ´ Ù†Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø³ØªÙˆÙ† Ù…ØªØºÛŒØ± Ù‡Ø¯Ù ÛŒØ¹Ù†ÛŒ <code>category</code> Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø±Ø¯.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# train['category'] = encoder.fit_transform(train['category'])\n",
    "# To-Do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Ø§Ú©Ù†ÙˆÙ† ÙˆÙ‚Øª Ø¢Ù† Ø±Ø³ÛŒØ¯Ù‡ Ú©Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯. Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¢Ø²Ø§Ø¯ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø¨ØªØ¯Ø§ Ù‡Ø± ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙ† Ø±Ø§ Ø¨Ù‡ Ú©Ù…Ú© ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø±ÙÛŒâ€ŒØ´Ø¯Ù‡ Ø¯Ø± Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† ÙØµÙ„ (Ù…Ø«Ù„ Bag-of-Word ÛŒØ§ Tf-idf) Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¹Ø¯Ø¯ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯. Ø³Ù¾Ø³ Ø§ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø±Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù„ÛŒØ³Øª Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ Ø¨Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ø¯Ù‡ÛŒØ¯ ØªØ§ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ®ØªÙ‡ Ø´ÙˆØ¯. Ø¹Ù„Ø§ÙˆÙ‡ Ø¨Ø± Ø§ÛŒÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªÙ…Ø§Ù… Ø§ÛŒÙ† Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ø¯Ø± ÛŒÚ© Ø®Ø· Ù„ÙˆÙ„Ù‡â€Œ (<code>Pipeline</code>) Ù†ÛŒØ² ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(loss=&#x27;hinge&#x27;, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(loss=&#x27;hinge&#x27;, max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(loss='hinge', max_iter=5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(loss='hinge', penalty='l2', max_iter=5000)\n",
    "model.fit(train_data, train_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "Ù…Ø¹ÛŒØ§Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ù…Ø¹ÛŒØ§Ø±ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒÙ…ØŒ <code>F1-score</code> Ù†Ø§Ù… Ø¯Ø§Ø±Ø¯ Ùˆ Ø§Ø² Ø±ÙˆÛŒÚ©Ø±Ø¯ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ ÙˆØ²Ù†â€ŒØ¯Ø§Ø± (<code dir=ltr>average='weighted'</code>) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "    <br>\n",
    "    Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø±ØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø± Ø±ÙˆÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÛŒ Ø¢Ù…ÙˆØ²Ø´ ÛŒØ§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø·Ø¨Ù‚ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡â€ŒØ¯Ø³Øªâ€ŒØ¢Ù…Ø¯Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ØªØ± ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8790416149149453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred_valid = model.predict(valid_data)\n",
    "f1_score(pred_valid, valid_data_target, average='weighted')\n",
    "# To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ù¾Ø³ Ø§Ø² Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ Ùˆ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…ÛŒ Ø¯Ø§Ø±ÛŒØ¯ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø´Ù…Ø§ Ø±Ø§ Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„ Ø¨Ù‡ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ø¨Ø±Ø³Ø§Ù†Ø¯.\n",
    "    <br>\n",
    "    Ø§Ø² Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± ÛŒÚ© Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… ØªÚ©â€ŒØ³ØªÙˆÙ†Ù‡ Ø¨Ø§ Ù†Ø§Ù… <code>submission</code> Ùˆ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø²ÛŒØ± Ø¢Ù…Ø§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. ØªÙˆØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ Ú©Ù‡ ØªØ±ØªÛŒØ¨ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ù…Ø§ Ø§Ù‡Ù…ÛŒØª Ø¯Ø§Ø±Ø¯ ÛŒØ¹Ù†ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø«Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ Ø¢Ø²Ù…ÙˆÙ† <code>m</code> Ø§Ù… Ø±Ø§ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø±Ø¯ÛŒÙ <code>m</code> Ø§Ù… Ø§ÛŒÙ† Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|Ø³ØªÙˆÙ†|ØªÙˆØ¶ÛŒØ­Ø§Øª|\n",
    "|:------:|:---:|\n",
    "|<code>category</code>|Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ø´Ù…Ø§ (Ø§Ø² Ø¬Ù†Ø³ Ø±Ø´ØªÙ‡)|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù‡Ù†Ø± Ùˆ Ø³Ø±Ú¯Ø±Ù…ÛŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù…ÙˆØ³ÛŒÙ‚ÛŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category\n",
       "0         Ù‡Ù†Ø± Ùˆ Ø³Ø±Ú¯Ø±Ù…ÛŒ\n",
       "1  Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª\n",
       "2  Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª\n",
       "3               Ù…ÙˆØ³ÛŒÙ‚ÛŒ\n",
       "4              Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(test_data)\n",
    "\n",
    "submission = pd.DataFrame() # To-Do\n",
    "submission['category'] = pred_test\n",
    "submission.replace({0: 'Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ', 1: 'Ø§Ø´ØªØºØ§Ù„', 2: 'ØªØ¬Ø§Ø±Øª Ùˆ Ø§Ù‚ØªØµØ§Ø¯', 3: 'ØªØ­ØµÛŒÙ„Ø§Øª', 4: 'ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ú©Ø§Ù…Ù¾Ø¨ÙˆØªØ±', 5: 'Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª', 6: 'Ø­ÛŒÙˆØ§Ù†Ø§Øª Ø®Ø§Ù†Ú¯ÛŒ', 7: 'Ø®Ø§Ù†Ù‡ Ùˆ Ø¨Ø§ØºØ¨Ø§Ù†ÛŒ', 8: 'Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡', 9: 'Ø®ÙˆØ¯Ø±Ùˆ', 10: 'Ø³ÙØ± Ùˆ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ', 11: 'Ø³Ù„Ø§Ù…Øª', 12: 'Ø¹Ù„Ù… Ùˆ Ø¯Ø§Ù†Ø´', 13: 'ØºØ°Ø§ Ùˆ Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ', 14: 'ÙÛŒÙ„Ù… Ùˆ Ø³ÛŒÙ†Ù…Ø§', 15: 'Ù…Ø¯ Ùˆ Ø²ÛŒØ¨Ø§ÛŒÛŒ', 16: 'Ù…Ø°Ù‡Ø¨ÛŒ', 17: 'Ù…Ø³Ú©Ù†', 18: 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ', 19: 'Ù‡Ù†Ø± Ùˆ Ø³Ø±Ú¯Ø±Ù…ÛŒ', 20: 'ÙˆØ±Ø²Ø´', 21: 'Ú©ØªØ§Ø¨ Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª'}, inplace=True)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>Ø³Ù„ÙˆÙ„ Ø¬ÙˆØ§Ø¨â€ŒØ³Ø§Ø²</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù† ÙØ§ÛŒÙ„ <code>result.zip</code> Ø³Ù„ÙˆÙ„ Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯. ØªÙˆØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ Ú©Ù‡ Ù¾ÛŒØ´ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„ Ø²ÛŒØ± ØªØºÛŒÛŒØ±Ø§Øª Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ø¯Ø± Ù†Øªâ€ŒØ¨ÙˆÚ© Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯ (<code>ctrl+s</code>) ØªØ§ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ù…Ú©Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø¯ Ø´Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['text_categorization.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['text_categorization.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ğŸ’­ Ø§Ø¶Ø§ÙÙ‡: Ø§Ø¨Ø±Ù Ú©Ù„Ù…Ø§Øª (Word Cloud)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<center>\n",
    "<img src=\"wordcloud.png\">\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ÛŒÚ©ÛŒ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø¬Ø§Ù„Ø¨ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù…ØªÙ† Ø¯Ø± Ù¾Ø§ÛŒØªÙˆÙ†ØŒ <a href=\"https://github.com/amueller/word_cloud\"><code>WordCloud</code></a> Ù†Ø§Ù… Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø¨Ø±ÛŒ Ø§Ø² Ù¾Ø±ØªÚ©Ø±Ø§Ø±ØªØ±ÛŒÙ† ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ…ØªÙ† Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ÛŒ Ø²ÛŒØ¨Ø§ Ø¨Ù‡ ØªØµÙˆÛŒØ± Ø¨Ú©Ø´ÛŒØ¯. Ø®ÙˆØ´Ø¨Ø®ØªØ§Ù†Ù‡ Ù†Ø³Ø®Ù‡â€ŒÛŒ ÙØ§Ø±Ø³ÛŒ Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù†ÛŒØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² <a href=\"https://github.com/alihoseiny/word_cloud_fa\">Ø§ÛŒÙ† Ù„ÛŒÙ†Ú©</a> Ø¨Ù‡ ØµÙØ­Ù‡â€ŒÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ Ø¢Ù† Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯. Ø­ØªÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¯Ù„Ø®ÙˆØ§Ù‡ ØªØµÙˆÛŒØ±ÛŒ Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‡Ø§ÛŒÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ ØªØ¯Ø§Ø¹ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡â€ŒÛŒ ØªØµÙˆÛŒØ± Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø´Ù…Ø§ Ø¨Ø§Ø´Ø¯.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cloud_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m----> 3\u001b[0m     cloud_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None"
     ]
    }
   ],
   "source": [
    "cloud_text = ''\n",
    "for text in train_data:\n",
    "    cloud_text += text + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud_fa import WordCloudFa\n",
    "\n",
    "wc = WordCloudFa(width=1200, height=800, persian_normalize=True, include_numbers=False, max_words=120, background_color='white', min_font_size=10, max_font_size=100)\n",
    "word_cloud = wc.generate(cloud_text)\n",
    "image = word_cloud.to_image()\n",
    "image.show()\n",
    "image.save('wordcloud.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ</b>\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    Û±. Ø§Ø² ØªÚ©Ù†ÛŒÚ© n-gram Ú©Ù…Ú© Ø¨Ú¯ÛŒØ±ÛŒØ¯.\n",
    "    <br>\n",
    "    Û². ØªÙˆØ§Ø²Ù† Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.\n",
    "    <br>\n",
    "    Û³. Ø¯Ø± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø®ÙˆØ¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø­Ø°Ù Ø­Ø±ÙˆÙ Ø§Ø¶Ø§ÙÙ‡ Ùˆ Ø§Ø¹Ø¯Ø§Ø¯ØŒ Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª ØªÙˆÙ‚ÙØŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ... Ø±Ø§ Ø¢Ø²Ù…Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯.\n",
    "</font>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
