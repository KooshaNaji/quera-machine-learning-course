{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data_preprocessed.csv')\n",
    "train_data_target = pd.read_csv('train_data_target_preprocessed.csv')\n",
    "test_data = pd.read_csv('test_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data, train_data_target, valid_data_target = train_test_split(train_data, train_data_target, test_size=.1, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BLUENOTEBOOK\\Desktop\\media\\ex\\qenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'max_depth': None, 'max_samples': None, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import recall_score, make_scorer\n",
    "\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=50)\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators' : [50, 60, 70, 80],\n",
    "    'max_depth': [None, 4, 8, 12],  \n",
    "    'bootstrap': [True], \n",
    "    'max_samples': [None, 10, 18, 30],  \n",
    "    # 'min_samples_split': [2, 5, 10], \n",
    "    # 'min_samples_leaf': [1, 2, 4],  \n",
    "}\n",
    "\n",
    "\n",
    "# scorer = make_scorer(recall_score, pos_label='p')\n",
    "\n",
    "\n",
    "grid_search_RF = GridSearchCV(model_RF, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "\n",
    "grid_search_RF.fit(train_data, train_data_target)\n",
    "\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_RF.best_params_)\n",
    "# print(\"Best Recall Score:\", grid_search_RF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = grid_search_RF.predict(train_data)\n",
    "pred_valid = grid_search_RF.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7820061483346423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Int       0.80      0.68      0.74     40161\n",
      "        Work       0.78      0.86      0.82     50754\n",
      "\n",
      "    accuracy                           0.78     90915\n",
      "   macro avg       0.79      0.77      0.78     90915\n",
      "weighted avg       0.79      0.78      0.78     90915\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27459 12702]\n",
      " [ 6883 43871]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score(train_data_target, pred_train, average='weighted')  # For multi-class problems, use 'weighted'\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(train_data_target, pred_train)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "cm = confusion_matrix(train_data_target, pred_train)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7520931389927118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Int       0.80      0.68      0.74     40161\n",
      "        Work       0.78      0.86      0.82     50754\n",
      "\n",
      "    accuracy                           0.78     90915\n",
      "   macro avg       0.79      0.77      0.78     90915\n",
      "weighted avg       0.79      0.78      0.78     90915\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27459 12702]\n",
      " [ 6883 43871]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score(valid_data_target, pred_valid, average='weighted')  # For multi-class problems, use 'weighted'\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(train_data_target, pred_train)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "cm = confusion_matrix(train_data_target, pred_train)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
